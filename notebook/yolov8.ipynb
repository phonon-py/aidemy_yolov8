{"cells":[{"cell_type":"markdown","metadata":{},"source":["- ディレクトリを移動する"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"9f2FOVLNC8LE"},"outputs":[{"name":"stdout","output_type":"stream","text":["C:\\Users\\041674\\VSCode\\YOLOv8\\ultralytics\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\041674\\VSCode\\YOLOv8\\venv\\Lib\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n","  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"]}],"source":["%cd C:\\Users\\041674\\VSCode\\YOLOv8\\ultralytics"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["C:\\Users\\041674\\VSCode\\YOLOv8\\ultralytics\n"]}],"source":["import os\n","\n","path = os.getcwd()\n","print(path)"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"EoEHfQAzC6Mf"},"outputs":[],"source":["from ultralytics import YOLO"]},{"cell_type":"markdown","metadata":{},"source":["# runフォルダ内のF1_curve.pngをTensorBoardに保存するための関数"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"JIVIAL29rxjZ"},"outputs":[],"source":["import tensorflow as tf\n","\n","\n","def save_image_tf(base_path, run):\n","    \"\"\"\n","    runフォルダ内の指定された画像をTensorBoardに保存する\n","\n","    base_path: モデルの結果のディレクトリ\n","    run: runフォルダの名前\n","    \"\"\"\n","    plot_list = ['F1_curve.png', 'confusion_matrix.png', 'PR_curve.png']\n","\n","    for plot_name in plot_list:\n","        run_dir = os.path.join(base_path, run)\n","        plot_path = os.path.join(run_dir, plot_name)\n","\n","        # PNGファイルをテンソルとして取得\n","        with open(plot_path, \"rb\") as plot_png:\n","            png_bytes = plot_png.read()\n","        image = tf.image.decode_png(png_bytes, channels=4)\n","        image = tf.expand_dims(image, 0)\n","\n","        # TensorBoardに画像ファイルを書き込む\n","        file_writer = tf.summary.create_file_writer(run_dir)\n","        with file_writer.as_default():\n","            tf.summary.image(f'{plot_name}', image, step=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HlUKsKUf1Xzs"},"outputs":[],"source":["# 事前学習済みモデルの重みを読み込む\n","model = YOLO(\"yolov8n.pt\")\n","\n","# エポック数を10にして訓練\n","run_name = 'epochs_10'  # コロンをアンダースコアに変更\n","\n","# 絶対パスを使用\n","data_path = r'C:\\Users\\041674\\VSCode\\YOLOv8\\ultralytics\\ultralytics\\cfg\\datasets\\raccoon-cat.yaml'\n","base_path = r'C:\\Users\\041674\\VSCode\\YOLOv8\\ultralytics\\ultralytics\\runs\\detect'\n","\n","results = model.train(data=data_path,\n","                      name=run_name,\n","                      epochs=10,\n","                      optimizer='Adam',\n","                      seed=1)\n","\n","# この関数は見直し\n","# save_image_tf(base_path, run_name)\n"]},{"cell_type":"markdown","metadata":{},"source":["# TensorBoardでデータを確認するときはコマンドラインを使用する"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# %tensorboard --logdir C:\\Users\\041674\\VSCode\\YOLOv8\\ultralytics\\runs\\detect\\epochs_103"]},{"cell_type":"markdown","metadata":{},"source":["# 2.3.1 エポック数を変えてみよう"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w8ogVp9jK289"},"outputs":[],"source":["# 事前学習済みモデルの重みを読み込む\n","model = YOLO(\"yolov8n.pt\")\n","# エポック数を10、学習率を0.004にして訓練\n","run_name = 'epochs_10_lr0.004'\n","results = model.train(data = 'raccoon-cat.yaml',\n","                      name = run_name,\n","                      epochs = 10,\n","                      optimizer = 'Adam',\n","                      seed = 1,\n","                      lr0 = 0.004,\n","                      lrf = 0.004\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BQAvaLnxLYbo"},"outputs":[],"source":["# 事前学習済みモデルの重みを読み込む\n","model = YOLO(\"yolov8n.pt\")\n","# エポック数を30にして訓練\n","run_name = 'epochs_30_lr0.004'\n","results = model.train(data = 'raccoon-cat.yaml',\n","                      name = run_name,\n","                      epochs = 30,\n","                      optimizer= 'Adam',\n","                      seed = 1,\n","                      lr0 = 0.004,\n","                      lrf = 0.004\n",")\n"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"9aqZSJ_ZNWuY"},"outputs":[{"name":"stdout","output_type":"stream","text":["Ultralytics YOLOv8.2.58  Python-3.12.2 torch-2.3.1+cpu CPU (Intel Core(TM) i5-10500T 2.30GHz)\n","\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=raccoon-cat.yaml, epochs=70, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=epochs_70_lr0.004, exist_ok=False, pretrained=True, optimizer=Adam, verbose=True, seed=1, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.004, lrf=0.004, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\epochs_70_lr0.004\n","Overriding model.yaml nc=80 with nc=2\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    751702  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n","Model summary: 225 layers, 3,011,238 parameters, 3,011,222 gradients, 8.2 GFLOPs\n","\n","Transferred 319/355 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\epochs_70_lr0.004', view at http://localhost:6006/\n","Freezing layer 'model.22.dfl.conv.weight'\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\041674\\VSCode\\YOLOv8\\datasets\\labels\\train.cache... 320 images, 0 backgrounds, 0 corrupt: 100%|██████████| 320/320 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\041674\\VSCode\\YOLOv8\\datasets\\labels\\val.cache... 80 images, 0 backgrounds, 0 corrupt: 100%|██████████| 80/80 [00:00<?, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Plotting labels to runs\\detect\\epochs_70_lr0.004\\labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.004, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n","Image sizes 640 train, 640 val\n","Using 0 dataloader workers\n","Logging results to \u001b[1mruns\\detect\\epochs_70_lr0.004\u001b[0m\n","Starting training for 70 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       1/70         0G      1.167      2.209      1.644         46        640: 100%|██████████| 20/20 [04:37<00:00, 13.88s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:23<00:00,  7.96s/it]"]},{"name":"stdout","output_type":"stream","text":["                   all         80         87    0.00477      0.956     0.0398     0.0149\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       2/70         0G      1.423      1.895       1.81         34        640: 100%|██████████| 20/20 [04:24<00:00, 13.22s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:24<00:00,  8.18s/it]"]},{"name":"stdout","output_type":"stream","text":["                   all         80         87     0.0565      0.275     0.0369    0.00922\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       3/70         0G      1.387      1.784      1.775         48        640: 100%|██████████| 20/20 [04:30<00:00, 13.54s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:24<00:00,  8.30s/it]"]},{"name":"stdout","output_type":"stream","text":["                   all         80         87      0.011      0.179     0.0264     0.0144\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       4/70         0G      1.477      1.785      1.864         38        640: 100%|██████████| 20/20 [04:26<00:00, 13.35s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:24<00:00,  8.22s/it]"]},{"name":"stdout","output_type":"stream","text":["                   all         80         87       0.51      0.456     0.0191    0.00699\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       5/70         0G      1.627      1.743       1.93         44        640:  10%|█         | 2/20 [00:27<04:09, 13.85s/it]"]}],"source":["# 事前学習済みモデルの重みを読み込む\n","model = YOLO(\"yolov8n.pt\")\n","# エポック数を70にして訓練\n","run_name = 'epochs_70_lr0.004'\n","results = model.train(data = 'raccoon-cat.yaml',\n","                      name = run_name,\n","                      epochs = 70,\n","                      optimizer = 'Adam',\n","                      seed = 1,\n","                      lr0 = 0.004,\n","                      lrf = 0.004\n",")\n","\n","save_image_tf(base_path, run_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U-kTgm7GLeyd"},"outputs":[],"source":["#TODO 事前学習済みモデルの重みを読み込む\n","model = YOLO(\"yolov8n.pt\")\n","# エポック数:30 / バッチサイズ:32にして訓練\n","run_name = 'epoch:30_batch:32_lr:0.004'\n","results = model.train(data = 'raccoon-cat.yaml',\n","                      name = run_name,\n","                      epochs = 30,\n","                      batch = 32,\n","                      optimizer = 'Adam',\n","                      seed = 1,\n","                      lr0 = 0.004,\n","                      lrf = 0.004\n",")\n","\n","save_image_tf(base_path, run_name)\n","%tensorboard --logdir /content/drive/MyDrive/ultralytics/runs/detect"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X6x7diNdOlJw"},"outputs":[],"source":["# 事前学習済みモデルの重みを読み込む\n","model = YOLO(\"yolov8n.pt\")\n","# エポック数:30 / バッチサイズ:32 / 学習率:0.0006にして訓練\n","run_name = 'epoch:30_batch:32_lr:0.0006'\n","results = model.train(data = 'raccoon-cat.yaml',\n","                      name = run_name,\n","                      epochs = 30,\n","                      batch = 32,\n","                      optimizer = 'Adam',\n","                      seed = 1,\n","                      lr0 = 0.0006,\n","                      lrf = 0.0006,\n","\n",")\n","\n","save_image_tf(base_path, run_name)\n","%tensorboard --logdir /content/drive/MyDrive/ultralytics/runs/detect"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"jNNROqkhI5A-"},"outputs":[],"source":["# epoch:30_batch:32_lr:0.0006の重みを読み込む\n","model = YOLO(\"/content/drive/MyDrive/ultralytics/runs/detect/epoch:30_batch:32_lr:0.0006/weights/best.pt\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gsIWJsZWDtVy"},"outputs":[],"source":["#テスト\n","results = model.predict(source = '/content/drive/MyDrive/pred_data/pred_image01.jpeg', data = 'raccoon-cat.yaml', save=True)\n","results = model.predict(source = '/content/drive/MyDrive/pred_data/pred_image02.jpeg', data = 'raccoon-cat.yaml', save=True)\n","results = model.predict(source = '/content/drive/MyDrive/pred_data/pred_image03.jpeg', data = 'raccoon-cat.yaml', save=True)\n","results = model.predict(source = '/content/drive/MyDrive/pred_data/pred_image04.jpeg', data = 'raccoon-cat.yaml', save=True)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMQ0TXmgIAYhfOv5iR1ibAT","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":0}
